{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation - Train Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul acestei secțiuni o să ne uităm mai mult peste partea de Cross Validation, la final o să aruncăm o privire și peste partea de Grid Search, iar ca ultimă parte o să finalizăm secțiunea cu proiectul pentru algoritmul de Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am terminat cu partea de curățare de date și pregătirea setului de date putem să creem un model de predicție de tip Linear Regression. Pentru a putea crea însă cel mai bun model mai trebuie să ne uităm peste două concepte teoretice și anume Cross Validation și Grid Search. Am discutat deja despre modele care au partea de Cross Validation implementate, cum ar fi RidgeCV și LassoCV. Modele respective au implementată partea de Cross Validation. Din păcate nu orice model din Scikit-Learn are partea de Cross Validation implementată automat în model, dar pentru a ne asigura că putem să realizăm etapa aceasta, Scikit-Learn are o metodă specifică de Cross Validation care se poate aplica la orice model. Această etapă ne permite ca după să facem partea de Grid Search pentru a găsi hyperparametrii optimi pentru modelul respectiv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a parcuge secșiunea complet o să începem din nou cu partea de Train-Test split pentru a ne putea aminit la ce anume se folosește și de ce este utilă această metodă. După cum știm, partea de train-test split se aplică pe un set de date (pregătit pentru algoritmul de machine learning) iar ca și output se împarte setul de date într-un set de date de antrenare și un set de date de testare. Se dorește să se facă acest lucru deoarece pentru a verifica performața unui model de Machine Learning trebuie să verificăm această performanșă pe un set de date neatins, pe care algoritmul nu l-a văzut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pe baza acestei performanțe a modelului (eroarea rezultată) putem să modificăm hyperparametrii modelului pentru a îl îmbunătăți. Să recapitulăm toate aceste operațiuni în Python și Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file into a DataFrame\n",
    "df = pd.read_csv('../data/DATA/Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the head of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mai jos o să scriem care sunt pașii care trebuie urmați pentru a crea un model de Machine Learning în Python utilizând Scikit-Learn\n",
    "\n",
    "1.  Curățarea setului de date\n",
    "\n",
    "2.  Împărțirea setului de date în train-test (pentru Features și Labels)\n",
    "\n",
    "3.  Antrenarea scalării datelor pentru setul de train(fit pe setul de antrenare)\n",
    "\n",
    "4.  Transformarea datelor utilizân acel Scaler creat și antrenat (fit pe setul de antrenare și testare)\n",
    "\n",
    "5.  Crearea/Alegerea unui model\n",
    "\n",
    "6.  Antrenarea modelului pe setul de date de antrenare\n",
    "\n",
    "7. Măsurarea performanței modelului\n",
    "\n",
    "8. Ajustarea parametrilor și rularea pașilor 6 și 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into Features and Labels\n",
    "X = df.drop('sales', axis=1)\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the train_test_spli method\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Standard Scaler from Scikit-Learn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the scaler to the test data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test sets using the scaler\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing a Ridge Regression model from sklearn\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of the Linear model\n",
    "linear_model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction\n",
    "y_pred = linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the error metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the errors\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 2.1631741364394363\n",
      "RMSE = 2.709571144855608\n"
     ]
    }
   ],
   "source": [
    "print(f'MAE = {MAE}')\n",
    "print(f'RMSE = {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am ales o valoare pentru parametrul de alpha destul de mare pentru a vedea că putem să facem partea de yperparameters tunning în funcție de performața unui model (pentru a putea face și ultimul pas din lista de mai sus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 1.2168768443580582\n",
      "RMSE = 1.5228334050147283\n"
     ]
    }
   ],
   "source": [
    "linear_model2 = Ridge(alpha=1)\n",
    "linear_model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear_model2.predict(X_test)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f'MAE = {MAE}')\n",
    "print(f'RMSE = {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am reușit să îmbunătățim modelul prin modificare hyperparametrului alpha. Utilizând însă partea de Train-Test split, metoda clasică și cea mai simplă este destul de greu să aflăm care model este cel mai bun deoarece după fiecare rulare ar trebuie să verificăm performanța modelului după care să alegem o nouă valore pentru parametrul de alpha și procesul ar tot trebui repetat. Avantajul metodei respective este faptul că este extrem de intuitivă, se poate înțelege ce anume se face prin cadrul acestei metode, iar partea de computație nu este una deloc solicitantă pentru mașina pe care se rulează"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
