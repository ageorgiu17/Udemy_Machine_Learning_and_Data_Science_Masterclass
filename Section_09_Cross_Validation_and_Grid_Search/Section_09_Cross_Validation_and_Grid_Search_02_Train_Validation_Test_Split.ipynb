{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation - Train  Validation  Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partea de Train-Test split are un dezavantaj mare și anume faptul că nu are o porțiune din setul de date care să fie cu adevărat 'neatinsă' și 'nevăzută' de către model pentru a putea face evaluare performanței unui anumit model. Deși partea de ajustare a hyperparametrilor utilizând setul de testare este extrem de folosită, aceasta totuși reprezintă o problemă în ceea ce privește partea de raportare a performanței modelului. Există o metodă prin care putem să prevenim această problemă."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă dorim întradevăr să avem un model la care să nu facem îmbunătățire de hyperparametrii pe baza setului de testare (care ar trebuie să fie doar pentru partea de raport), există o calea și de a face acest lucru. Începem din nou cu setul de date întreg pe care îl avem. În loc să împărțim setul de date doar în train-test, acum mai adăugăm încă o categorie care poartă denumirea de valodation set. În acest moment o să avem trei noi categorii de seturi de date, train, validation și test. Procentajul în care distribuim setul de date depinde de mărimea setului de date inițial. Se dorește ca în setul de date de testare (test set) să fie un număr destul de reprezentativ de date pe care se poate testa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce avem aceste seturi de date, se pune deoparte setul de date de testare (test set), se antrenează un model pe setul de date de antrenare și se verifică performanța modelului (eroarea) pe setul de validare. Dacă nu suntem mulțumiți de performanța modelului atunci creem un nou model, îl reantrenăm pe setul de date de antrenare după care verificăm din nou performanaț modelului tot pe setul de date de verificare (validation set). În momentul în care sutem pe deplin mulțumiți de performanța modelului se mai rulează un nou set de predicții pe setul de date de testare și se evaluează modelul. După această evaluare nu mai avem voie să modificăm hyperparametrii modelului, eroare care rezultă pe setul de date de testare trebuie să fie cea care este raportată mai departe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a obține acest comportament în Python tot ce trebuie să facem este să rulăm metoda train_test_split() de două ori. După ce am rulat prima dată metoda și avem două seturi de date (train și test) mai rulăm încă odată metoda, însă de această dată doar pentru setul de test. Acest set îl împărțim acuma în validation set și test set. De setul de date 'test' nu trebuie să ne atingem până la final. Să implementăm toate acestea în Python și Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data into a DataFrame\n",
    "df = pd.read_csv('../data/DATA/Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the head of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into Features and Labels\n",
    "X = df.drop('sales', axis=1)\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split method from sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data the first time into train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum că am apelat metoda train_test_split() prima dată avem două seturi de date, train (X_train, y_train) și test (X_test și y_test). Setul de date de testare o să îl mai împărțim încă odată utilizând din nou metoda train_test_split(). Diferența la aceasta a doua utilizare este faptul că nu o să utilizăm același procent de împărțire. O să împărțim setul de date de testare astfel încât să fie o rație de 50-50 (validation - test) sau 66-34 (validation - test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data the second time into validation-test sets\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În acest moment, după ce am rulat metoda de train_test_split() și a doua oară, acuma avem următoarele seturi de date:\n",
    "\n",
    "1.  X_train (train set) = care reprezintă 70% din setul de date mare (df)\n",
    "\n",
    "2.  X_validation (validation set) = care reprezintă 15% din setul de date mare (df)\n",
    "\n",
    "3.  X_test (test set) = care reprezintă 15% din setul de date mare (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pașii care trebuie făcuți în continare sunt următorii:\n",
    "\n",
    "- crearea unui scaler\n",
    "\n",
    "- antrenarea scaler-ului (pe datele de antrenare)\n",
    "\n",
    "- trainsformarea datelor (pe toate cele trei seturi de date)\n",
    "\n",
    "- crearea modelului\n",
    "\n",
    "- evaluarea modelului (pe setul de date de validare)\n",
    "\n",
    "- tunarea modelului\n",
    "\n",
    "- chiar la final (după ce suntem mulțumiți cu performața modelului) trebuie evaluat modelul pe setul de date de testare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mporting the StandardScaler from sklearn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of the StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the scaler only in train set\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming all the data with the fitted scaler\n",
    "X_train = scaler.transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the Ridge model from Scikit-Learn\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of the model\n",
    "ridge1_model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model on X_train (train set)\n",
    "ridge1_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am creat și am atrenat un model de Ridge Regression, urmează partea de evaluare a modelului. Știm că inițial pentru partea de evaluare a unui model se făceau predicții pe un set de date, iar acele predicții erau comparate cu valorile adevărate de labels. Acest procedeu se făcea pentru setul de date de testare. Din moment ce am zis că partea de validare unui model pentru îmbunătățirea de hyperparametrii se va face utilizând setul de validare, acuma trebuie să folosim setul de validare pentru a face predicții și tot pentru acest set de validare o să calculăm erorile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_pred = ridge1_model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 2.1754243744399884\n",
      "RMSE = 2.7055686017589484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "MAE = mean_absolute_error(y_validation, y_validation_pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_validation, y_validation_pred))\n",
    "\n",
    "print(f'MAE = {MAE}')\n",
    "print(f'RMSE = {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am verificat performanța modelului utilizând setul de date de validare, dacă nu suntem mulțumiți de rezltat putem să creem alt model cu alți hyperparametrii pentru a vedea dacă există ceva îmbunătățiri. O să creeem un nou model de Ridge Regression, de data aceasta cu valoarea 1 pentru parametrul de alpha și o să ăl evaluăm tot pe setul de date de validare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 1.195143424023704\n",
      "RMSE = 1.5439504768796786\n"
     ]
    }
   ],
   "source": [
    "ridge2_model = Ridge(alpha=1)\n",
    "ridge2_model.fit(X_train, y_train)\n",
    "\n",
    "y_validation_pred = ridge2_model.predict(X_validation)\n",
    "\n",
    "MAE = mean_absolute_error(y_validation, y_validation_pred)\n",
    "RMSE = np.sqrt(mean_squared_error(y_validation, y_validation_pred))\n",
    "\n",
    "print(f'MAE = {MAE}')\n",
    "print(f'RMSE = {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am modificat prametrii și suntem mulțumiți de rezultat putem să facem o nouă serie de predicții finale pentru setul de date de testare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 1.2386102646924124\n",
      "RMSE = 1.5014193564093001\n"
     ]
    }
   ],
   "source": [
    "y_pred = ridge2_model.predict(X_test)\n",
    "\n",
    "MAE = mean_absolute_error(y_pred, y_test)\n",
    "RMSE = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "print(f'MAE = {MAE}')\n",
    "print(f'RMSE = {RMSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se poate vedea că performața modelului este diferită pentru validation set și test set. După ce am evaluat modelul pe test set nu mai avem voie să modificăm hyperparametrii modelului, perrformanța acestuia o să fie stailită ca fiind eroarea rezultată după evaluare modelului pe setul de date de testare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapitulare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul acestui tutorial am învățat următoarele lucruri:\n",
    "\n",
    "    1. Existența unui validation set este necesară deoarece partea de verificare a performanței modelului și îmbunătățirea acestuia trebuie realizată după evaluarea modelului pe acest set de validare\n",
    "\n",
    "    2. Cum să împărțim setul de date în seturile de antrenare, testare și validare\n",
    "\n",
    "        X_train, X_validation_test, y_train, y_validation_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        X_validation, X_test, y_validation, y_test = train_test_split(X_validation_test, y_validation_test, test_size=0.5, random_state=42)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
