{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urmează partea în care o să ne uităm peste metoda cross_val_score din Scikit-Learn ce ne permite să realizăm Cross Validation pentru orice model. Utilizând asta nu mai trebuie să ne facem griji dacă modelul respectiv are implementat sau nu partea de Cross Validation (precum are implementat Ridge și Lasso care au versiunea de CV - ce provine de la Cross Validation). Pentru început o să revizuim partea de Cross Validation (K-Fold cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Știm că pentru un set de date îl împărțim în set de date de train și test. Până în secțiunea aceasta am utilizat setul de testare și pentru partea de evaluare a performanței modelului, abia acuma am început să reținem o porțiune din setul de date pentru partea de evaluare a performanței (validation set). În ceea ce părivește cross-validation, prima dată este împărțit setul de date din nou în train-test set. Setul de testare este pus deoparte și nu trebuie să ne atingem de el. Cu ceea ce rămâne, adică setul de antrenare, trebuie să alegem o valoare pentru acel parametru de K-fold (în metoda de 'cross_val_score' poartă denumirea de cv). Acest parametru o să împartă setul de antrenare în atâtea părți câte îi oferim ca și valoare pentru acel parametru K-fold. Dacă îi oferim valorea 5 de exemmplu, atunci setul de antrenare o să fie împărțit în 5 seturi separate. Se face antrenarea folosind primele 4 seturi, iar validarea se va face pe ultimul set, după se va face antrenarea pe primele 3 și ultimul set, iar setul 4 va fi utilizat pentru validare. Se va repeta acest procedeu până ce se face validarea pentru fiecare set în parte (din cele 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoda cross_val_score din Scikit-Learn are nevoie de un model și un set de date de antrenare, împreună cu parametrul de K-fold (care poartă denumirea de cv). Acest procedeu funcționează cu orice model din Scikit-Learn și se realizează extrem de simplu și rapid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../SS/cross_validation.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginea de mai sus reprezintă partea de cross-validation. Cu verde sunt prezentate seturile de date pe care se antrenează, iar cu albastru sunt seturile de date de validare. Se poate observa că utilizând partea de cross validation, modelul este antrenat și validat pe fiecare set de date. Din moment ce setul de date a fost împărțit în 5 (K-fold=5) o să se realizeze partea de antrenare a modelului de 5 ori. În funcție de setul de date cu care se lucrează trebuie să alegem numărul de k-folds. Dacă avem un set mare de date și alegem o valoare mare pentru k-fold, atunci o să dureze extrem de mult partea aceasta de cross_validation. Eroarea de verificare a modelului o să fie media celor 5 erori. În funcție de aceasta se modifică hyperparametrii modelului și la final se testează pe setul de date de testare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Să realizăm partea de cross-validation în Python și Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data into a DataFrame\n",
    "df = pd.read_csv('../data/DATA/Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the head of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and labels\n",
    "X = df.drop('sales', axis=1)\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the train_test_split method from Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Înainte de a crea un model trebuie din nou să ne importăm un scaler și să realizăm partea de scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the scaler from sklearn\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of the scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the scaler to the train data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the data with the scaler\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the Ridge model from Scikit-Learn\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of the model\n",
    "model = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Până în acest moment, totul este identic cu ce s-a făcut anterior. Am luat datele, le-am transformat (cu un StandardScaler) după care am creat un model. De aici însă lucrurile încep să fie diferite. Trebuie să importăm metoda cross_val_score din Scikit-Learn pentru început. Aceasta se găsește în submodulul model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cross_val_score in module sklearn.model_selection._validation:\n",
      "\n",
      "cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
      "    Evaluate a score by cross-validation.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : estimator object implementing 'fit'\n",
      "        The object to use to fit the data.\n",
      "    \n",
      "    X : array-like of shape (n_samples, n_features)\n",
      "        The data to fit. Can be for example a list, or an array.\n",
      "    \n",
      "    y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "        The target variable to try to predict in the case of\n",
      "        supervised learning.\n",
      "    \n",
      "    groups : array-like of shape (n_samples,), default=None\n",
      "        Group labels for the samples used while splitting the dataset into\n",
      "        train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "        instance (e.g., :class:`GroupKFold`).\n",
      "    \n",
      "    scoring : str or callable, default=None\n",
      "        A str (see model evaluation documentation) or\n",
      "        a scorer callable object / function with signature\n",
      "        ``scorer(estimator, X, y)`` which should return only\n",
      "        a single value.\n",
      "    \n",
      "        Similar to :func:`cross_validate`\n",
      "        but only a single metric is permitted.\n",
      "    \n",
      "        If `None`, the estimator's default scorer (if available) is used.\n",
      "    \n",
      "    cv : int, cross-validation generator or an iterable, default=None\n",
      "        Determines the cross-validation splitting strategy.\n",
      "        Possible inputs for cv are:\n",
      "    \n",
      "        - `None`, to use the default 5-fold cross validation,\n",
      "        - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "        - :term:`CV splitter`,\n",
      "        - An iterable that generates (train, test) splits as arrays of indices.\n",
      "    \n",
      "        For `int`/`None` inputs, if the estimator is a classifier and `y` is\n",
      "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "        other cases, :class:`KFold` is used. These splitters are instantiated\n",
      "        with `shuffle=False` so the splits will be the same across calls.\n",
      "    \n",
      "        Refer :ref:`User Guide <cross_validation>` for the various\n",
      "        cross-validation strategies that can be used here.\n",
      "    \n",
      "        .. versionchanged:: 0.22\n",
      "            `cv` default value if `None` changed from 3-fold to 5-fold.\n",
      "    \n",
      "    n_jobs : int, default=None\n",
      "        Number of jobs to run in parallel. Training the estimator and computing\n",
      "        the score are parallelized over the cross-validation splits.\n",
      "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "        for more details.\n",
      "    \n",
      "    verbose : int, default=0\n",
      "        The verbosity level.\n",
      "    \n",
      "    fit_params : dict, default=None\n",
      "        Parameters to pass to the fit method of the estimator.\n",
      "    \n",
      "    pre_dispatch : int or str, default='2*n_jobs'\n",
      "        Controls the number of jobs that get dispatched during parallel\n",
      "        execution. Reducing this number can be useful to avoid an\n",
      "        explosion of memory consumption when more jobs get dispatched\n",
      "        than CPUs can process. This parameter can be:\n",
      "    \n",
      "            - ``None``, in which case all the jobs are immediately\n",
      "              created and spawned. Use this for lightweight and\n",
      "              fast-running jobs, to avoid delays due to on-demand\n",
      "              spawning of the jobs\n",
      "    \n",
      "            - An int, giving the exact number of total jobs that are\n",
      "              spawned\n",
      "    \n",
      "            - A str, giving an expression as a function of n_jobs,\n",
      "              as in '2*n_jobs'\n",
      "    \n",
      "    error_score : 'raise' or numeric, default=np.nan\n",
      "        Value to assign to the score if an error occurs in estimator fitting.\n",
      "        If set to 'raise', the error is raised.\n",
      "        If a numeric value is given, FitFailedWarning is raised.\n",
      "    \n",
      "        .. versionadded:: 0.20\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    scores : ndarray of float of shape=(len(list(cv)),)\n",
      "        Array of scores of the estimator for each run of the cross validation.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn import datasets, linear_model\n",
      "    >>> from sklearn.model_selection import cross_val_score\n",
      "    >>> diabetes = datasets.load_diabetes()\n",
      "    >>> X = diabetes.data[:150]\n",
      "    >>> y = diabetes.target[:150]\n",
      "    >>> lasso = linear_model.Lasso()\n",
      "    >>> print(cross_val_score(lasso, X, y, cv=3))\n",
      "    [0.33150734 0.08022311 0.03531764]\n",
      "    \n",
      "    See Also\n",
      "    ---------\n",
      "    cross_validate : To run cross-validation on multiple metrics and also to\n",
      "        return train scores, fit times and score times.\n",
      "    \n",
      "    cross_val_predict : Get predictions from each split of cross-validation for\n",
      "        diagnostic purposes.\n",
      "    \n",
      "    sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      "        loss function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cross_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se poate observa că metoda cross_val_score() are un număr de parametrii importanți, și anume, estimator, X, y, cv și scoring. Estimator se referă la modelul pe care îl folosim pentru a realiza cross-validation (un model este doar un estimator, el estimează anumite valori). Prin urmare aici trebuie să oferim ca și valoare modelul creat mai sus (estimator=Ridge, sau se poate oferi doar simplu Ridge). X și y sunt datele de antrenare, features și labels. cv reprezintă valoarea pentru K-folds, în câte seturi să împartă datele de antrenare. Dacă nu se oferă nicio valoare, atunci o să meargă pe opțiunea de leave-one-out prin care se validează modelul cu o singură valorea din acel set de date. Dacă avem 1000 de valori, o să se antreneze pe 999 și validarea se va face pe o valoare. Se va repeta acest proces până când se validează pe fiecare valoare din setul de date. scoring face referire la ce metrică să folosească pentru partea de validare. Se merge pe ideea de valoare mai mare reprezintă un model mai bun, de aceea pentru metricii de mean_square_error și mean_absolute_error se va returna valoarea negatică (neg_mean_sqaured_error, neg_mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.32552967,  -4.9449624 , -11.39665242,  -7.0242106 ,\n",
       "        -8.38562723])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După cum spuneam, ceea ce se retunrează este valoarea negativă de la mean_squared_error, de aceea valorile sunt cu minus. Putem să transformăm aceste valori în valori pozitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.32552967,  4.9449624 , 11.39665242,  7.0242106 ,  8.38562723])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spuneam că valoarea erorii care trebuie considerată corectă este valoarea medie pentru fiecare valiadre în parte, de aceea pentru array-ul scores trebuie să accesăm media (scores.mean()). Pentru a fi o valoarea pozitivă o să ne folosim din nou de metoda abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.215396464543607"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valoarea medie a erorii este 8.21, ceea ce nu este bine. Putem să modificăm valoarea pentru hyperparametrul alpha. În continuare o să modificăm valoarea să fie 1 și o să realizăm din nou partea de cross-validation. Pentru asta o să creem un nou model (model=Ridge(alpha=1)) și se va rerula codul de cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Ridge(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = cross_val_score(model2, X_train, y_train, scoring='neg_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.344839296530695"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(scores2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am modificat valoarea pentru aplha la 1 calitatea modelului a crescut. Ce este interesant la această metodă este faptul că nu returnează un model care este antrenat (pe care s-a apelat metoda .fit()). Pentru a crea un model antrenat și a face predicții trebuie să antrenăm acel model și să facem predicțiile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5228334050147283"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapitulare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul acestei lecții am învățat:\n",
    "\n",
    "    1. De unde să importăm metoda cross_val_score\n",
    "\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    2. De ce parametrii are nevoie metoda pentru a funcționa\n",
    "\n",
    "        estimator = modelul pe care dorim să îl folosim\n",
    "\n",
    "        X = setul de date de antrenare pentru features\n",
    "\n",
    "        y = setul de date de antrenare pentru labels\n",
    "\n",
    "        scoring = metrica pe care să o folosească pentru evaluarea modelului\n",
    "\n",
    "        cv = numărul de K-folds în care să împartă setul de date de antrenare\n",
    "\n",
    "    3. Cum să utilizăm metoda cross_val_score\n",
    "\n",
    "        scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "    4. Cum să aflăm media erorilor modelului\n",
    "\n",
    "        abs(scores.mean())\n",
    "\n",
    "    5. Modelul nu este antrenat, pentru a face predicții finale la final de cross-validation trebuie să antrenăm modelul și să facem predicții pentru setul de date de testare\n",
    "\n",
    "        model.fit(X_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
