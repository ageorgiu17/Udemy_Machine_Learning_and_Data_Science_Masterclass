{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În următoarele secțiuni o să ne focusăm pe partea de tree based models. Există trei mari categorii, iar acestea sunt:\n",
    "\n",
    "1. Decison Tree\n",
    "\n",
    "2. Random Forest\n",
    "\n",
    "3. Boosted Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiecare metodă provine de la Decision Tree, prin urmare o să începem cu această metodă. O să parcurgem fiecare metodă în cadrul unei secțiuni separate, iar la final o să avem un proiect."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmii de Decesion Tree se bazează pe abilitatea de a splitui datele pe baza informațiilor pe care le preiau din anumiți features. Prin asta avem nevoie de o definiție matematică a informației și abilitatea de a măsura acea informație. O să aruncăm o privire peste modul în care funcționează acest algoritm de Decision Tree."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../SS/decision_tree2.png'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avem imaginea de mai sus. Imaginea respectivă putem să zicem că este o reprezentare a unor date numerice, unde Dosage (ceea ce este cu albastru) reprezintă Features, iar ceea ce este cu verde este outputul algoritmului, adică label-ul. Să zicem că avem un element care are o anumită valaore pentru Dosage, valoarea 10. Prima dată algoritmul verifică dacă valoarea este mai mică sau nu de 14. Pentru valoarea aleasă aceasta este mai mică de 14 (este 10), prin urmare merge în ramura de True. Dacă 10 este mai mic decât 14 returnează True, respectiv invers. Din moment ce a mers pe ramura de True, vedem că algoritmul retunrează un output, și anume acel label de 'effective' la care îi pune valoarea de 4.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aceste ramuri se pot tot ramifica după cum se poate observa. Dacă alegem o valoare de 20, algoritmul merge pe ramura de False. În acea ramură nu se oferă un rezultat, ci se mai face o comparație. Algoritmul verifică dacă valoarea pentru dosage este mai mare sau egală cu 29. În funcție de câte ramuri are, algoritmul parcurge acele ramuri până ce ajunge la un anumit rezultat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a înțelege mai bine partea de Decision Trees prima dată o să ne uităm peste terminologia care se va folosi:\n",
    "\n",
    "1. Splitting = preluarea unor date într-un anumit nod (Node) și luarea decizie dacă acea condițier rezultă cu True sau False\n",
    "\n",
    "2. Node = To ce se vede în imaginea de mai sus (cu verde și albastru) reprezintă un Node\n",
    "\n",
    "3. Root Node = Nodul care se găsește la baza algoritmului. Reprezintă prima condiție (feature) pe baza căruia se va face acel splitting\n",
    "\n",
    "4. Leaf (Terminal) Node = Reprezintă nodul unde nu se mai face acel Splitting, aici este stabilită valoarea pentru acel label (căsuțele cu verde reprezintă Leaf Node în imaginea de mai sus)\n",
    "\n",
    "5. Parent and Children Node = Rezultatul Splitting-ului unui Node rezultă în două Children Nodes. Nodul care este splituit poartă denumirea de Parent Node\n",
    "\n",
    "6. Pruning = teoria prin care putem face acest algoritm de Decision Tree mai scurt. Idea din spatele acestui procedeu este de a ajuta partea de Overfitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a înțelege cum partea de slitting funcționează în crearea algoritmului de Decision Tree o să aruncăm o privire peste factorul de măsurare a informațiilor, și anume 'gini impurity'. Acest concept este unul matematic de măsurare a calității 'pure' a infomației dintr-un set de date. Putem să ne imaginăm ca o unitate de măsurare a uniformității unei clase."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../SS/gini.png'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecuația de mai sus reprezintă ecuația de calcul pentru gini impurity. Pare o ecuație complicată, însă aceasta este destul de simplă, măsoară numărul de clase pe care îl avem și mixtura purității dintre acestea. Ca să înțelegem o să luăm un exemplu cu două clase și în fiecare clasă o să avem câte două elemente. Trebuie să aplicăm formula aceea pentru fiecare clasă în parte."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clasa 1 = (2/4)(1 - 2/4) = 0.25\n",
    "\n",
    "clasa 2 = (2/4)(1 - 2/4) = 0.25\n",
    "\n",
    "gini impurity = 0.25 + 0.25 = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unde (2/4) = 2 două elemente sunt în clasa 1 dintr-un total de 4 elemente"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valoarea de 0.5 este valoarea maximă pe care o putem avea pentru acest gini impurity, iar aceasta apare atunci când avem un număr egal de valori în clasele cu care lucrăm. Dacă schimbăm valorile pentru elementele din clasele respective, unde în clasa 1 o să avem 1 element și în clasa 2 o să avem 3 elemente, atunci setul de date o să fie mai pur în ceea ce privește uniformizarea claselor, iar ecuația o să arate în felul următor:\n",
    "\n",
    "clasa 1 = (1/4)(1 - 1/4) = 0.1875\n",
    "\n",
    "clasa 2 = (3/4)(1 - 3/4) = 0.1875\n",
    "\n",
    "gini impurity = 0.1875 + 0.1875 = 0.375"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putem să vedem că acuma valoarea pentru gini impurity a scăzut la 0.375 de la 0.5. Dacă setul de date era complet pur, adică toate elementele făceau parte din clasa 2, atunci am fi avut o impuritate de 0 (gini impurity = 0), și asta pentru faptul că nu avem deloc impuritate de clase, toate elementele din acel set de date fac parte dintr-o singură clasă, prin urmare setul de date este cât se poate de pur."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă scopul unui algoritm de Decision Tree este să separe clase, atunci trebuie să avem o valoare pentru gini impurity cât mai apropiată de 0. Dacă avem o valoare mică de gini impurity la Leaf Nodes, atunci înseamnă că separăm clasele eficient. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| X - URL Link | Spam |\n",
    "| --- | --- |\n",
    "| Yes | Yes |\n",
    "| Yes | Yes |\n",
    "| No  | No  |\n",
    "| No  | No  |\n",
    "| No  | Yes |\n",
    "| No  | No  |\n",
    "| Yes | No  |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O să lucrăm acuma cu un set de date mai mic, în care avem 7 intrări. Setul de date reprezintă informațiile cum că un anumit mail este spam sau nu. Ca și feature pentru acest set de date avem URL-link unde specificăm dacă mail-ul pe care l-am primit conține un link sau nu. În coloana Spam avem label-ul pentru acest set de date care ne spune dacă email-ul respectiv a fost sau nu spam. Splituirea pentru acest feature se face în două, și anume dacă email-ul a conținut un URL-link sau nu."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O să luăm prima dată cazul în care email-ul a conținut un link. Pentru acest caz există 3 intrări în setul de date (3 email-uri), iar dintre acestea 2 au fost Spam, iar 1 nu a fost.\n",
    "\n",
    "URL-Link = Yes\n",
    "\n",
    "Spam:\n",
    "\n",
    "    - Yes = 2\n",
    "\n",
    "    - No = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru email-urile care nu au conținut un link, avem 4 cazuri, iar dintre acestea 3 sunt Spam, iar unul nu este"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL-Link = No\n",
    "\n",
    "Spam:\n",
    "\n",
    "    - Yes = 1\n",
    "\n",
    "    - No = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă un anumit feature are o valaore mare a impurității, atunci se recomandă să se facă split după acel feature deoarece astfel, prin acest split se va obține o puritate mai bună a claselor. În acest exemplu o să avem un Decision Tree care are două Leaf Nodes, și anume atunci când email-ul conține un URL-Link sau nu. Pentru fiecare dintre aceste Leaf Nodes putem să calculăm valoarea pentru gini impurity, deoarece avem două clase în fiecare Leaf Node. \n",
    "\n",
    "În primul Node (atunic când email-ul conține un URL-link) avem următoarele valori:\n",
    "\n",
    "(2/3)(1 - 2/3) + (1/3)(1 - 1/3) = 0.44 (gini impurity)\n",
    "\n",
    "În al doilea Node (atunci când email-ul nu conține un URL-Link) avem următoarele valori:\n",
    "\n",
    "(3/4)(1 - 3/4) + (1/4)(1 - 3/4) = 0.375 (gini impurity)\n",
    "\n",
    "Valorile de mai sus sunt valorile de Gini Impurity pentru fiecare Leaf Node. Trebuie însă să calculăm valoare aceasta pentru întreg-ul feature, iar formula de calcul este următoarea:\n",
    "\n",
    "(3/7) * 0.44 + (4/7) * 0.375 = 0.403\n",
    "\n",
    "(3/7) reprezintă număr de elemente din primul Leaf Node împărțit la număr total de elemente din setul de date. \n",
    "\n",
    "În concluzie avem o valoare de 0.403 pentru acest Feature. Ce se întâmplă în situația în care avem mai multe features sau avem un feature de tip continuu? Ce facem când avem un feature categoric cu mai multe cateogrii?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| X - Word counts | Spam |\n",
    "| --- | --- |\n",
    "| 10 | Yes |\n",
    "| 20 | Yes |\n",
    "| 30  | No  |\n",
    "| 40  | No  |\n",
    "| 50  | No |\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În setul de date de mai sus avem un feature de tip continu în care ne este prezentat numărul de cuvinte din fiecare email. Pentru a putea începe să calculăm acest gini impurity pentru acest tip de feature prima dată trebuie să aranjăm datele în ordine crescătoare (sunt deja prezente așa). În acest moment trebuie să alegem un număr arbitrat după care să împărțim datele (pe baza căruia să facem split-ul de date). O modalitate este de a lua valoarea medie dintre două elemente consecutive din setul de date. Primul element are valoarea 10, iar al doilea are 20. Valoarea medie a acestor două numere este de 15. Prin urmare putem să considerăm valoarea 15 pentru a face split între acele date. Dacă se face split între datele respective o să ajungem din nou la mometul în care avem două leaf nodes pentru care putem să caluclăm valoarea pentru gini impurity. Valoarea respectivă este doar pentru valoarea 15 după care se împarte setul de date. Pentru a avea o acuratețe cât mai mare trebuie să calculăm valoarea de gini impurity pentru fiecare valoare medie dintre două valori consecutive. Valoarea cea mai mică de gini impurity o să fie luată în considerare pentru a crea acel Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru cazurile de multi-class feature, o să luăm exemplul de mai jos:\n",
    "\n",
    "| X - Sender | Spam |\n",
    "| --- | --- |\n",
    "| Abe | Yes |\n",
    "| Bob | Yes |\n",
    "| Claire | No  |\n",
    "| Abe  | No  |\n",
    "| Bob  | No |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Din moment ce avem categorii de text și nu avem date numerice, atunic pentru a împărți datele într-un Node o să alegem comparatorul de ==. Verificăm dacă cel care a trimis mail-ul este pentru început 'Abe' (Sender == Abe). Această comparație ne împarte setul de date în două și putem din nou să calculăm valoarea de gini impurity. O să facem același lucru pentru fiecare dintre valorile prezente în cadrul acestui set de date. De asemenea putem combina mai multe valori din cadrul acestui set de date. De exemplu putem să întrebăm dacă cel care a trimis mail-ul este Abe sau Bob (Sender == Abe or Bob). După ce am parcurs toate combinațiile posibile o să selectăm valoarea cea mai mică pentru gini impurity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru un set de date cu mai multe features, modelul calculează acel gini impurity pentru fiecare feature în parte, iar ca și Root Node acel feature-ul care are cea mai mică valoare deoarece dorim ca acel feature din Root Node să ne separe date cât mai pur posibil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5 (v3.10.5:f377153967, Jun  6 2022, 12:36:10) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
