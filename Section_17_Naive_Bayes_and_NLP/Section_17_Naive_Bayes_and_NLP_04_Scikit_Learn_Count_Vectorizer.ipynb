{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În partea precedentă am creat manula codul pentru Count Vectorization. Urmează să facem acest lucru acuma cu Scikit-Learn. O să ne uităm peste trei clase specifice și anume:\n",
    "\n",
    "1. Count Vectorizer\n",
    "\n",
    "2. TF-IDF Transformer\n",
    "\n",
    "3. TF-IDF Vectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru acest exemplu o să lucrăm o listă care o să conțină trei string-uri diferite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['This is a line',\n",
    "        'This is another line',\n",
    "        'Completley different line']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În continuare o să creem acel bag of words model, dar de data asta utilizând Scikit-Learn, mai specific o să ne folosim de clasa 'CountVectorizer' care se găsește în sklearn.feature_extraction.text. O să importăm această clasă"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trebuie să creem o instanță pentru această clasă, iar după o să apelăm metoda fit_transform() pentru acea listă de sring-uri. Ceea ce o să facă aceast cod, o să trateze fiecare element din listă (adică fiecare string) ca pe un document separat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit_transform(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cele ce urmează o să discutăm despre diferența dintre fit și fit_transform și cum să citim documente mai multe sau mai mari. Din rezultatul de mai sus observăm faptul că 'fit_transform' returnează un sparse matrix deoarece multe dintre datele din rezultat au valoarea 0, iar prin intermediul unui sparse matrix reușim să salvăm spațiu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = cv.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă salvăm rezultatul într-o variabilă, atunci când o apelăm aceasta doar ne returnează informația cum că este o matrice de tip sparse matrix. În cazul în care dorim să vizualizăm datele din această matrice putem apela metoda .todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 1, 1, 1],\n",
       "        [1, 0, 0, 1, 1, 1],\n",
       "        [0, 1, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix.todense()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cu ajutorul acestei metode reușim să vizualizăm rezultatul. De notat însă faptul că nu este recomandat să utilizăm această metodă atunci când lucrăm cu un număr extrem de mare de date. Datele din acea matrice reprezintă ceea ce am creat precedent manual și fac referire la acel vocabular cu care am lucrat. Putem să vizualizăm vocabularul utilizând atributul .vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 5, 'is': 3, 'line': 4, 'another': 0, 'completley': 1, 'different': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificatorii pentru cuvintele din dicționar fac referire la locația din acea matrice. De exemplu, putem vedea că în dicționar cuvântul 'another' are identificatorul 0, Dacă ne uităm în cadrul matricei, pentru index-ul 0, doar pentru rândul 2 avem o valoare diferită de zero (valoarea 1). Asta ne spune că acel cuvânt cu index-ul 0 din dicționar a apărul 1 dată în al doilea document și niciodată în celelalte două documente. Dacă ne uităm la conținutul variabilei text putem confirma acest lucru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a line', 'This is another line', 'Completley different line']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doar al doilea string din aceastp listă are prezent cuvântul 'another'. În cazul acestor documente există și anumite cuvinte care sunt destul de comune și e normal să apară în orice document (acele stop words de care am menționat ăn lecturile precedente). Pentru a elimina aceste cuvinte, clasa de CountVectorizer are impelementat parametrul de stop_words la care putem să îi oferim ca și valoare fie 'english' (care reprezintă un dicționar de cuvinte comune din limba Engleză), fie să îi oferim o listă de valori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "sparse_matrix = cv.fit_transform(text)\n",
    "sparse_matrix.todense()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Din moment ce acuma am folosit parametrul de 'stop_words=\"english\"' se poate observa faptul că există doar trei valori în matrice, ceea ce înseamnă că există doar trei cuvinte în cadrul vocabularului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'line': 2, 'completley': 0, 'different': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceea ce dorim să facem în continuare cu acest bag of words care a rezultat este să facem acea comparație între documente, să vedem dacă există anumite cuvinte care sunt specifice pentru fiecare document sau anumite cuvinte care sunt specifice pentru toate documentele. Pentru asta o să utilizăm un TF-IDF Transformer. Pe acesta îl importăm tot din sklearn.feature_extraction.text și poartă denumirea de TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoda de fit_transform() de la această clasă ia ca și input un sparse matrix, adică rezultatul acelui CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tfidf.fit_transform(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După cum putea vedea, se returnează din nou doar un sparse matrix. Dacă dorim (din moment ce are o memeorie mică) putem să afișăm acea matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 1.        ],\n",
       "        [0.        , 0.        , 1.        ],\n",
       "        [0.65249088, 0.65249088, 0.38537163]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.todense()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce am aplicat această transformare se poate observa că valorile au fost modificate. Pentru a ne ușura treaba, Scikit-Learn are și o clasă de TfidfVectorizer care face ambii pași deodată. Tot ce trebuie să facem este să importăm acea clasă, să creem o instanță și să utilizăm metoda fit_transform() pe datele respective (adică pe variabila text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.61980538, 0.48133417,\n",
       "         0.61980538],\n",
       "        [0.63174505, 0.        , 0.        , 0.4804584 , 0.37311881,\n",
       "         0.4804584 ],\n",
       "        [0.        , 0.65249088, 0.65249088, 0.        , 0.38537163,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tfidf_v.fit_transform(text)\n",
    "result.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapitulare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul acestei lecții am învățat următoarele lucruri:\n",
    "\n",
    "    1. De unde să importăm clasa de CountVectorizer\n",
    "\n",
    "        from sklearn.feature_extractor.text import CountVectorizer\n",
    "\n",
    "    2. Cum să folosim clasa de CountVectorizer\n",
    "\n",
    "        cv = CountVectorizer()\n",
    "\n",
    "        cv.fit_transform(text)\n",
    "\n",
    "    3. Ce returnează metoda fit_transform\n",
    "\n",
    "        Metoda returnează un sparse matrix pentru o econimisi spațiu\n",
    "\n",
    "    4. Cum putem să transformă un spare matrix înapoi într-o matrice densă \n",
    "\n",
    "        results = cv.fit_transform(text)\n",
    "\n",
    "        results.todense()\n",
    "\n",
    "    5. Cum putem să utilizăm conceptul de stop_words pentru a elimina cuvintele comnue dintr-o anumită limbă\n",
    "\n",
    "        cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "    6. De unde să importăm clasa de TfidfTransformer\n",
    "\n",
    "        from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "    7. De ce anume are nevoie această clasă și cum se utilizează\n",
    "\n",
    "        Metoda de fit_transform() de la TfidfTransformer are nevoie de rezultatul de la CountVectorizer pentru a funcționa\n",
    "\n",
    "        cv = CountVectorizer()\n",
    "\n",
    "        tfidf = TfidfTransformer()\n",
    "\n",
    "        cv_result = cv.fit_transformt(text)\n",
    "\n",
    "        tfidf_result = tfidf.fit_transform(cv_results)\n",
    "\n",
    "    8. Pașii de mai sus putem să îi realizăm cu o singură clasă, cea de TfidfVectorizer\n",
    "\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "        tfidf_v = TfidfVectorizer()\n",
    "\n",
    "        tfidf_v_result = tfidf_v.fit_transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
