{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction from Text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După cum spuneam, un model clasic de Machine Learning nu poate să extragă informații din texte. Trebuie să performăm un așa numit 'featute extraction' din acele date stocate ca și text. În urma acestui proces o să extragem valori numerice din aceste date pe care după putem să le oferim modelului ca să le proceseze. Există două metode pentru a extrage aceste informații din texte, iar acestea sunt:\n",
    "\n",
    "1. Count Vectorization (prin care se numără fiecare cuvânt din acel text)\n",
    "\n",
    "2. TF-IDF (Term Frequency - Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "## Count Vectorization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prin procesul denumit Count Vectorization o să creem un vocabular care conține toate cuvintele din anumite documente și o să numărăm de câte ori apare fiecare cuvânt în toate documentele."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Documents |\n",
    "| --- |\n",
    "| You are good |\n",
    "| I fell good   |\n",
    "| I am good   |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Din aceste documente o să reiasă următorul vocabular: \n",
    "\n",
    "- You\n",
    "\n",
    "- are\n",
    "\n",
    "- good\n",
    "\n",
    "- I\n",
    "\n",
    "- fell\n",
    "\n",
    "- am"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru fiecare dintre aceste cuvinte putem să numărăm de câte ori apare cuvântul respectiv într-un document\n",
    "\n",
    "| Documents/Dictionary | You | are | good | I | fell | am |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| You are good | 1 | 1 | 1 | 0 | 0 | 0 |\n",
    "| I fell good   | 0 | 0 | 1 | 1 | 1 | 0 |\n",
    "| I am good   | 0 | 0 | 1 | 1 | 0 | 1 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acest procedeu de Count vectorization tratează fiecare cuvânt în parte ca și pe un feature individual, iar cu cât acel cuvânt are un count mai mare într-un document se va considera că acel cuvânt/feature are o importanță mai mare. Din cauza faptului că la anumite documente mari o să avem o mulțime de valori cu 0, datele care sunt extrase din acest algoritm o să fie salvate în 'sparse matrix'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O să enumerăm problemele care apar la acest algoritm. Există extrem de multe cuvinte comune cum ar fi 'a', 'the', 'about', iar aceste cuvinte comune reprezintă o anumită problemă. Pentru rezolvarea acestei probleme s-a creat noțiunea de Stop Words. Acestea reprezintă cuvinte extrem de comune dintr-o limbă, prin urmare nu ne ajută să extragem informații despre aceste cuvinte și se pot elimina. Majoritatea modelelor de NLP au deja implementat un set de valori care fac parte din aceste Stop Words\n",
    "\n",
    "O altă problemă reprezintă repetarea de cuvinte în anumite documente care au un anumit subiect de discuție. De exemplu, cuvântul 'run' o să apară extrem de mult într-un document care are ca și idee principală un articol din atletism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problema care apare la acest tip de algoritm este faptul că se face această vectorizare doar pentru un singur document. După cum spuneam, cuvântul 'run' poate să apară de multe ori într-un document care are ca și subiect de discuție un articol de atletism, dar în restul documentelor nu mai apare. Ar fi ideal dacă am putea să ne uităm și la conținutul celorlalte documente. Aici intră în calcul TD-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce anume face acest algoritm? Pentru cuvintele care sunt comune în toate documentele și apar de multe ori, o să scadă 'greutatea' (weight)(importanța) acelui cuvânt doarece prezența acelui cuvânt nu ne ajută să distingem diferența dintre anumite documente deoarece apare extrem de des. În comparație, dacă există anumite cuvinte specifice pentru un anumit sport de exemplu, atunci acele cuvinte specifice, de specialitate o să apară doar în documentele care vorbesc doar despre așa ceva. Din acest motiv importanaț acestor cuvinte o să crească deoarce prin ele putem să facem disticția între documente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
