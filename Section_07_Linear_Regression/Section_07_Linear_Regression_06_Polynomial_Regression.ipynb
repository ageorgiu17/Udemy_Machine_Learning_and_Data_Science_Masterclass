{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Până în acest moment am completat un model de Machine Learning de tipul Linear Regression, am văzut cum se crează un model, pe ce date se antrenează (train set), cum se fac predicții și cum se poate verifica performanța unui model (prin folosirea de metrici, RMSE). Cum se poate îmbunătăți acest model? Un mod de a îmbunătăți un model este prin utilizarea unei relații de grad mai mare între Features. Aici intră în calcul ideea de Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial Regression o să ne returneze două idei:\n",
    "\n",
    "- Non-linear features relationship to label\n",
    "\n",
    "- Interaction term between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear features realationship to label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Să ne imaginăm că avem un feature din setul de date care nu este liniar (nu există o corelație liniară între puncte, ci mai degrabă una curbată). Având o linie care este mai curbată, este greu să găsim o relație liniară pentru aceste features. În momentul în care se ridică la pătrat acel feature, atunci linia resepctivă o să fie mai apropiată de o linie dreaptă. Dacă numărul cu care se ridică la pătrat este mai mare, atunci linia aceea va deveni tot mai dreatpă. Acest concept ne permită să găsim coeficienții beta de care avem nevoie pentru a crea o regresie liniară. Putem aplica această metodă atunci când corelația dintre features și labels nu este una liniară, prin ridicarea la putere putem să creem mai ușor o linie dreaptă de regresie care să ne găsească un coeficient beta mai corect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este de reținut însă faptul că nu fiecare feature o să aibă astfel de relații (relații liniare) la un grad mai mare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acest termen face referire la ideea cum că un anumit feature este de interes doar dacă este combinat cu un alt feature. (asta poartă denumirea de synergy în domeniul de buisiness). Să luăm un exemplu din DataFrame-ul pe care l-am avut. Din feature-urile pe care le avem , să zicem că publicitatea din ziare nu are un efect atâta de important pentru vânzările finale, dar combinat cu cel de radio are un efect mai mare. Cum anume se poate verifica dacă două features combinate au o influență mai mare decât individual?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cel mai simplu mod este de a crea un nou feature care multiplică cele două features de interes (sau care credem că ar avea un efect mai important dacă sunt combinate). Se pot păstra feature-urile inițiale precum și ceea ce a rezultat din multiplicarea acestor features. Din fericire Scikit-Learn ne pune la dispoziție un modul de preprocesare de date unde se găsește și această parte de Polynomial Regression. (poartă denumirea de PolynomialFeatures). Metoda respectiă atât ne creează intracțiunea dintre ele cât și ridicarea la pătrat pentru feicare feature în parte (în funcție de ordinea de degree pe care o alegem). În continuare o să experimentăm aceste terorii în Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reafing the data\n",
    "df = pd.read_csv('../data/08-Linear-Regression-Models/Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the head of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partea aceasta de Polynomial Features ține mai mult de Feature Regression. Primul pas este să separăm Features de labels din cadrul acestui set de date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the fetures from the labels\n",
    "X = df.drop(columns='sales')\n",
    "y = df['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum vine partea de Polynomial Regression. Acest procedeu se va face cu ajutorul modului de preprocessing din Scikit-Learn de unde o să importăm PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acest procedeu funcționează precum un model de Mahine Learning, trebuie să creem o instanță pentru PolynomialFeatures împreună cu anumiți parametrii, dacă dorim să îi schimbăm, după care se antrenează acea instanță utilizând metoda .fit(). Să aruncăm întâi o privire peste parametrii care sunt disponibili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PolynomialFeatures in module sklearn.preprocessing._polynomial:\n",
      "\n",
      "class PolynomialFeatures(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  PolynomialFeatures(degree=2, *, interaction_only=False, include_bias=True, order='C')\n",
      " |  \n",
      " |  Generate polynomial and interaction features.\n",
      " |  \n",
      " |  Generate a new feature matrix consisting of all polynomial combinations\n",
      " |  of the features with degree less than or equal to the specified degree.\n",
      " |  For example, if an input sample is two dimensional and of the form\n",
      " |  [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <polynomial_features>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  degree : int or tuple (min_degree, max_degree), default=2\n",
      " |      If a single int is given, it specifies the maximal degree of the\n",
      " |      polynomial features. If a tuple `(min_degree, max_degree)` is passed,\n",
      " |      then `min_degree` is the minimum and `max_degree` is the maximum\n",
      " |      polynomial degree of the generated features. Note that `min_degree=0`\n",
      " |      and `min_degree=1` are equivalent as outputting the degree zero term is\n",
      " |      determined by `include_bias`.\n",
      " |  \n",
      " |  interaction_only : bool, default=False\n",
      " |      If `True`, only interaction features are produced: features that are\n",
      " |      products of at most `degree` *distinct* input features, i.e. terms with\n",
      " |      power of 2 or higher of the same input feature are excluded:\n",
      " |  \n",
      " |          - included: `x[0]`, `x[1]`, `x[0] * x[1]`, etc.\n",
      " |          - excluded: `x[0] ** 2`, `x[0] ** 2 * x[1]`, etc.\n",
      " |  \n",
      " |  include_bias : bool, default=True\n",
      " |      If `True` (default), then include a bias column, the feature in which\n",
      " |      all polynomial powers are zero (i.e. a column of ones - acts as an\n",
      " |      intercept term in a linear model).\n",
      " |  \n",
      " |  order : {'C', 'F'}, default='C'\n",
      " |      Order of output array in the dense case. `'F'` order is faster to\n",
      " |      compute, but may slow down subsequent estimators.\n",
      " |  \n",
      " |      .. versionadded:: 0.21\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  powers_ : ndarray of shape (`n_output_features_`, `n_features_in_`)\n",
      " |      `powers_[i, j]` is the exponent of the jth input in the ith output.\n",
      " |  \n",
      " |  n_input_features_ : int\n",
      " |      The total number of input features.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          This attribute is deprecated in 1.0 and will be removed in 1.2.\n",
      " |          Refer to `n_features_in_` instead.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_output_features_ : int\n",
      " |      The total number of polynomial output features. The number of output\n",
      " |      features is computed by iterating over all suitably sized combinations\n",
      " |      of input features.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SplineTransformer : Transformer that generates univariate B-spline bases\n",
      " |      for features.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Be aware that the number of features in the output array scales\n",
      " |  polynomially in the number of features of the input array, and\n",
      " |  exponentially in the degree. High degrees can cause overfitting.\n",
      " |  \n",
      " |  See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n",
      " |  <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.preprocessing import PolynomialFeatures\n",
      " |  >>> X = np.arange(6).reshape(3, 2)\n",
      " |  >>> X\n",
      " |  array([[0, 1],\n",
      " |         [2, 3],\n",
      " |         [4, 5]])\n",
      " |  >>> poly = PolynomialFeatures(2)\n",
      " |  >>> poly.fit_transform(X)\n",
      " |  array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
      " |         [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
      " |         [ 1.,  4.,  5., 16., 20., 25.]])\n",
      " |  >>> poly = PolynomialFeatures(interaction_only=True)\n",
      " |  >>> poly.fit_transform(X)\n",
      " |  array([[ 1.,  0.,  1.,  0.],\n",
      " |         [ 1.,  2.,  3.,  6.],\n",
      " |         [ 1.,  4.,  5., 20.]])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PolynomialFeatures\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, degree=2, *, interaction_only=False, include_bias=True, order='C')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute number of output features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted transformer.\n",
      " |  \n",
      " |  get_feature_names(self, input_features=None)\n",
      " |      DEPRECATED: get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      " |      \n",
      " |      Return feature names for output features.\n",
      " |      \n",
      " |          Parameters\n",
      " |          ----------\n",
      " |          input_features : list of str of shape (n_features,), default=None\n",
      " |              String names for input features if available. By default,\n",
      " |              \"x0\", \"x1\", ... \"xn_features\" is used.\n",
      " |      \n",
      " |          Returns\n",
      " |          -------\n",
      " |          output_feature_names : list of str of shape (n_output_features,)\n",
      " |              Transformed feature names.\n",
      " |  \n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Input features.\n",
      " |      \n",
      " |          - If `input_features is None`, then `feature_names_in_` is\n",
      " |            used as feature names in. If `feature_names_in_` is not defined,\n",
      " |            then names are generated: `[x0, x1, ..., x(n_features_in_)]`.\n",
      " |          - If `input_features` is an array-like, then `input_features` must\n",
      " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Transformed feature names.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform data to polynomial features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data to transform, row by row.\n",
      " |      \n",
      " |          Prefer CSR over CSC for sparse input (for speed), but CSC is\n",
      " |          required if the degree is 4 or higher. If the degree is less than\n",
      " |          4 and the input format is CSC, it will be converted to CSR, have\n",
      " |          its polynomial features generated, then converted back to CSC.\n",
      " |      \n",
      " |          If the degree is 2 or 3, the method described in \"Leveraging\n",
      " |          Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices\n",
      " |          Using K-Simplex Numbers\" by Andrew Nystrom and John Hughes is\n",
      " |          used, which is much faster than the method used on CSC input. For\n",
      " |          this reason, a CSC input will be converted to CSR, and the output\n",
      " |          will be converted back to CSC prior to being returned, hence the\n",
      " |          preference of CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      XP : {ndarray, sparse matrix} of shape (n_samples, NP)\n",
      " |          The matrix of features, where `NP` is the number of polynomial\n",
      " |          features generated from the combination of inputs. If a sparse\n",
      " |          matrix is provided, it will be converted into a sparse\n",
      " |          `csr_matrix`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  n_input_features_\n",
      " |      DEPRECATED: The attribute `n_input_features_` was deprecated in version 1.0 and will be removed in 1.2.\n",
      " |  \n",
      " |  powers_\n",
      " |      Exponent for each of the inputs in the output.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      " |      and returns a transformed version of `X`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input samples.\n",
      " |      \n",
      " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      " |          Target values (None for unsupervised transformations).\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(PolynomialFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca și parametrii avem următorii: degree, intraction_only, include_bias și order. Degree reprezintă ordinul la care dorim să ridicăm la putere această ecuație, iar în mod default este setat la 2. Pe viitor o să avem o discuție despre cum să alegem cea mai bună valoare pentru acest parametru. Pentru interaction_only putem să specificăm dacă dorim să ne returneze doar interacțiunea dintre featrues, fără a mai ridica la putere fiecare feature în parte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_converter = PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum, această instanță de PolynomialFeatures așteaptă să fie antrenată pe un anumit set de date. Ce anume înseamnă antrenarea în acest caz, doar preia valorile pentru Features și le analizează, nu o să realizeze acele calcule (transformare) decât doar atunci când îi cerem explicit asta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(include_bias=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_converter.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De notat faptul că în acest caz nu trebuie să împărțim setul de date în train și test deorece acesta nu este un model, este doar parte de procesare de features. Prin acest .fit() programul doar a luat datele și s-a uitat peste ele, nu a realizat niciun calcul. Pentru a transforma datele respective în rezultatele unei ecuații polynomial de gradul 2 trebuie să apelăm metoda .transform(). Ca și argument o să îi oferim același set de date ca și la metoda .fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 230.1 ,   37.8 ,   69.2 , ..., 1428.84, 2615.76, 4788.64],\n",
       "       [  44.5 ,   39.3 ,   45.1 , ..., 1544.49, 1772.43, 2034.01],\n",
       "       [  17.2 ,   45.9 ,   69.3 , ..., 2106.81, 3180.87, 4802.49],\n",
       "       ...,\n",
       "       [ 177.  ,    9.3 ,    6.4 , ...,   86.49,   59.52,   40.96],\n",
       "       [ 283.6 ,   42.  ,   66.2 , ..., 1764.  , 2780.4 , 4382.44],\n",
       "       [ 232.1 ,    8.6 ,    8.7 , ...,   73.96,   74.82,   75.69]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_converter.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mai sus se poate observa rezultatul acelei metode transform(). Putem să verificăm forma acelui obioect care a fost returnat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_converter.transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putem vedea că ceea ce se retunrează este un obiect care are 200 de rânduri și 9 coloane. Ce anume înseamnă asta, este un rezultat bun? Putem să comparăm cu setul de date inițiat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambele seturi de date au același număr de rânduri, ceea ce este bine. Să vedem ce reprezintă acele 9 coloane care au fost returnate. Cum anume s-a ajuns la 9 coloane din 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = polynomial_converter.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TV           230.1\n",
       "radio         37.8\n",
       "newspaper     69.2\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.301000e+02, 3.780000e+01, 6.920000e+01, 5.294601e+04,\n",
       "       8.697780e+03, 1.592292e+04, 1.428840e+03, 2.615760e+03,\n",
       "       4.788640e+03])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O să ne uităm la valorile din primul element din setul de date inițial și primul element din setul de date care a fost returnat în urma transformării. Au sens valorile respecitve? Primele trei valori din setul de date ce a fost returnat (din primul element) reprezintă valorile pentru fiecare feature din setul de date inițial. Valoarea 2.301000e+02 practiv înseamnă să mutăm virgula cu două valori spre dreapta, ceea ce rezultă în 230.1000, care este la fel cu valoarea din TV de la primul element. Celelalte două valori (3.780000e+01, 6.920000e+01) reprezintă radio și newspaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Întrebarea este ce reprezintă celelalte 6 valori? 3 dintre acestea reprezintă interacțiunea dintre features, adică valorile a două features înmulțite. Să vedem ce se retunrează dacă se înmulțește (interacțiune) dintre TV și radio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8697.779999999999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "230.1 * 37.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă ne uităm în setul de date returnat, putem vedea că există valoarea 8.697780e+03, de unde acel +03 reprezintă numărul din față înmulțit cu 10 la puterea a 3-a, adică se mută virgula cu 3 valori înspre dreapta, care rezultă în 8697.78 ceea ce reprezintă defapt interacțiunea dintre TV și radio. Trei dintre aceste șase valori rămase reprezintă această interacțiune. Ultimele trei valori care au rămas reprezintă valoarea feature-ului ridicată la puterea 2 (valoarea care s-a ales pentru parametrul degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52946.009999999995"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "230.1 ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.294601e+04 reprezintă valoare pentru 230.1 ridicată la pătrat. Prin urmare, este corect să avem un număr de 9 coloane care ne sunt returnate după ce datele au fost transformate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Să revenim la partea de transformare. Este comun ca un anumit modul din Scikit-Learn să îți ceară prima dată datele ca să le vizualizeze (metoda .fit()) iar abia după să îi specifici să facă transformarea pentru datele respective, aceste module ne pun la dispoziție metoda .fit_transform() care face aceste lucruri în același timp, deoarece este atât de des întâlnit să se folosească fit împreună cu transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_results = polynomial_converter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 230.1 ,   37.8 ,   69.2 , ..., 1428.84, 2615.76, 4788.64],\n",
       "       [  44.5 ,   39.3 ,   45.1 , ..., 1544.49, 1772.43, 2034.01],\n",
       "       [  17.2 ,   45.9 ,   69.3 , ..., 2106.81, 3180.87, 4802.49],\n",
       "       ...,\n",
       "       [ 177.  ,    9.3 ,    6.4 , ...,   86.49,   59.52,   40.96],\n",
       "       [ 283.6 ,   42.  ,   66.2 , ..., 1764.  , 2780.4 , 4382.44],\n",
       "       [ 232.1 ,    8.6 ,    8.7 , ...,   73.96,   74.82,   75.69]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Această transformare se va face pe întreg setul de date deoarece constă în partea de pregătire a datelor. După ce se face această pregătire, transformare atunci se va împărți setul de date în train-test pentru a fi antrenat un model, a se face predicții cu acel model și a se evalua modelul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapitulare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul acestei părți am învățat următoarele lucruri:\n",
    "\n",
    "    1. Posibilitatea de a utiliza un Polynomial Regression pentru situațiile în care nu se potrivește un Linear Regression. Atunci când avem o linie care nu este dreaptă, ci curbată\n",
    "\n",
    "    2. Ce anume se retunrează în urma unui Polynomial Regression\n",
    "\n",
    "        interacțiunea dintre features\n",
    "\n",
    "        valorea ridicată la pătrat pentru fiecare feature\n",
    "\n",
    "    3. Cum să importăm această regresie\n",
    "\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "    4. Cum să instanțiem o astfel de regresie\n",
    "\n",
    "        polynomial_conerter = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "    5. Cum să specificăm pe ce date o să se realizeze această transformare\n",
    "\n",
    "        polynomial_converter.fit(X)\n",
    "\n",
    "            Această metodă de fit doar se utiă peste datele pe care o să le utilizăm\n",
    "\n",
    "    6. Cum să transformăm datele\n",
    "\n",
    "        polynomial_converter.transform(X)\n",
    "\n",
    "    7. Posibilitatea de a folosi .fit() și .transform() cu o singură metodă\n",
    "\n",
    "        polynomial_converter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
