{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptul de regularizare are de plan să rezolve anumite probleme din Machine Learning, cum ar fi:\n",
    "\n",
    "- Să minimizeze complexitatea modelului\n",
    "\n",
    "- Să penalizeze procestul de loss function\n",
    "\n",
    "- Să reducă partea de Overfit (adaugă mai mult bias pentru a reduce din variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul acestor mici lecții o să ne uităm peste următoarele concepte de regularizare:\n",
    "\n",
    "- L1 Regularization\n",
    "\n",
    "    - LASSO Regression\n",
    "\n",
    "- L2 Regularization\n",
    "\n",
    "    - Ridge Regression\n",
    "\n",
    "- Combined L1 and L2\n",
    "\n",
    "    - Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Înainte de a putea discuta anumite noțiuni tehnice și practice despre partea de reglarizare, trebuie să amintim alte două concepte importante, și anume Feature Scaling și Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptul de Feature Scaling ne oferă multe beneficii în cadrul procesului de Machine Learning. Unele modele de algoritmi chiar necesită acest concept să fie aplicat înainte de a antrena anumite date pentru a performa la un nivel bun (precul algoritmul de KNN). Ce anume reprezintă acest concept de Feature Scaling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Să luăm un exemplu. Dacă avem anumite features care au intervale de valori diferite și încercăm să folosim Gradient Descent pentru a afla coeficienții optimi pentru un agloritm, unele valori pentru coeficienți pot să se updateze mai rapid deoarece valoarea din fiecare feature are un rol destul de important. Ce se dorește este ca toate features să fie în mare măsură pe același interval de valori. Cam asta este partea de Feature Scaling (în mare măsură). Este în corelație cu Gradient Descent și face ca algoritmul să funcționeze cât mai optim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partea aceasta în care se modifică features pentru ca acestea să aibă cam același interval este importantă și pentru compararea coeficienților în mod direct. Deși acest concept pare unul destul de simplu, există anumite avertismente pe care trebuie să le luăm în considerare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă se antrenează un model în care am realizat conceptul de Features Scaling, asta înseamnă că de fiecare dată când îi oferim date noi pentru acel algoritm trebuie să realizăm această parte de Feature Scaling. Fără partea de Feature Scaling, când ne uitam la un anumit coeficient puteam să zicem că valoarea aceea reprezenta procentul (unitatea) de influență pentru un feature. Din moment ce am realizat partea de Feature Scaling nu mai putem să zicem că un feature modifică cu un anumit procent (o anuimită unitate) rezultatul final deoarece acum acel coeficient se referă la o porție din feature-ul respectiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca și avantaje, poate să ducă la o performanță mai bună a modelului, acest pas este uneori necesar pentru anumite modele (astfel nu se poate rula modelul respectiv), în teorie, nu este niciun efect negativ pentru acest concept de Feature Scaling. Există două metode prin care se poate face partea de Feature Scaling, și anume Normalization și Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizarea reprezintă procedeul prin care se face rescale la date astfel încât să aibă o valoare medie de 0 și o deviație standard de 1. Prin acest fel, pot exista și valori negative. Există anumite cazuri când se folosește termenul de Normalizare, dar pentru procestul de Standardizare. Acest proces mai portă și denumirea de Z-score normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prin normalizare, se rescalează datele astfel încât acestea să fie cuprinse între valoarea 0 și 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librăria de Scikit-Learn ne pune la dispoziție mai multe metode de Feature Scaling pentru datele cu care se lucrează. Această librărie ne pune la dispoziție clase care preformează metodele de 'fit()' și 'transform()'. Metoda 'fit()' calculează statisticile necesare, cum ar fi valoarea maximă, minimă, deviația standard, valoarea medie, etc. Pentru procestul de standardizare, metoda fit o să calculeze valorea medie și deviația standard. Metoda care face calculele și returnează noile date este metoda 'transform()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce este important de reținut la partea de Feature Scaling pentru metodele de fit și transform, este faptul că trebuie să apelăm metoda .fit() numai pentru datele de antrenare. După ce am apelat această metodă pentru datele de antrenare, abia după apelăm metoda .transform() pentru datele de antrenare pentru a antrena modelul. Este important de reținut să nu utilizăm metoda .fit() pentru tot setul de date, deoarece prin acest procedeul se întâmplă ceea ce în Machine Learning este cunoscut sub denumirea de Data Leackage. Dacă apelăm metoda fit pentru întreg setul de date, atunci poate algoritmul la partea de predicții o să știe valoare absolută a datelor sau deviația standard, ceea ce nu este tocmai ok. Partea de feature scaling trebuie utilizată în următorii pași:\n",
    "\n",
    "1. train-test-split\n",
    "\n",
    "2. fit to train set\n",
    "\n",
    "3. transform train set\n",
    "\n",
    "4. train the model\n",
    "\n",
    "5. transform test set\n",
    "\n",
    "6. make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptul de Cross Validation reprezintă o metodă mai avansată pentru a împărți setul de date în train și test sets. (pe viitor o să avem și o lecție de cross validation ce ține de sklearn). Pe moment o să ne uităm doar peste anumite concepte teoretice deoarece multe tehnici de regularuizare vin însoțite de o clasă care realizează acest cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Până în acest moment am afalt necesitatea de a împărți setul de date în train și test, dar prin acest procedeul nu putem să tunăm hyperparametrii unui model pe întreg setul de date, trebuie să reținem o porțiune din setul de date pentru partea de testare. Prin cross validation există posibilitatea de a antrena pe tot setul de date și de evalua modelul tot pe întreg setul de date. Cum funcționează acest concept de cross validation? Acesta a apărut de la întrebarea cum putem să antreăm un model pe întreg setul de date și cum putem să evaluăm un model tot pe întreg setul de date?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O să luăm un întreg set de date pe care o să îl împărțim într-un număr egal de părți (un număr K, adică K grupe a câte X elemente). Un grup din acestea K rămâne pentru partea de testare. Dacă alegem să împărțim setul de date într-un număr de 10 grupe, atunci un grup din acestea 10 rămâne pentru testare, iar restul de 9 se folosesc pentru antrenare. Pentru acest set de date (adică pentru ultimul grup K) o să calcuăm eraorea care ne interesează. După asta, în loc să folosim ultimul grup pentru testare, de data aceasta o să folosim penultimul, folosind restul de 9 grupuri pentru antrenare și se asemenea se calculează eroarea pentru acest grup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acest tip de validare ne oferă ca și rezultat media tuturor erorilor, medie care reprezintă cea mai apropiată de performanța adevărată a modelului deoarece am testat acest model pentru fiecare element din setul de date în parte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partea negativă pentru acest tip de validare este faptul că poate dura extrem de mult uneori până se rulează o asemenea validare deoarece trebuie să executăm un număr K de computații. Acest tip de validare mai poartă denumirea și de K-fold cross-validation. De cele mai multe ori, se oferă o valoare de 10 pentru K (dar nu este obligatoriu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru partea de antrenare și testare până în acest moment am avut un set de date împărțit în train-test. Se antrena un model folosind datele de antrenare după care se făceau predicții pe datele de testare. În funcție de acele rezultate de pe datele de testare se ajustează hyperparametrii unui model. Acest lucru nu este tocmai util uneori, deorece după ce se modifică hyperparametrii, se antrenează din nou și se fac noi predicții, practic modelul a mai văzut odată datele pentru care se fac predicții, ceea ce uneori poate nu este tocmai util. Din acest motiv trebuie să găsim o soluție prin care să se facă predicții pe un set de date care nu a mai fost niciodată văzut de către model. Pentru asta, acum o să împărțim setul de date în 3 părți. O să ne luăm o parte din setul de date (undeva la 10%) pe care nu o să îl atingem până la partea finală, cea de raport pentru model. Acest set de date poartă denumirea de holdout test set. Cu restul de 90% din setul de date ce a rămas, acesta se împarte fie în trai-test, fie se va face un cross-validation. Practic, cu restul de 90% din date se va proceda ca și până acuma în mod normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prin urmare o să avem următoarele seturi de date:\n",
    "\n",
    "- train set (~60%)\n",
    "\n",
    "- validation set (~30%) - fostul test set\n",
    "\n",
    "- test set/ holdout test set (~10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3a3a6ef3c8b7e46899d4c945da248f12dfe85847045d03c208cca8e54addeb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
